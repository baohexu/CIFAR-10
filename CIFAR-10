import jax
import jax.numpy as jnp
from flax import nnx
import optax
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np

BATCH_SIZE = 64
LEARNING_RATE = 3e-4
EPOCHS = 10
DEVICE = jax.devices()[0]

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

train_loader = DataLoader(
    datasets.CIFAR10("./data", train=True, download=True, transform=transform),
    batch_size=BATCH_SIZE, shuffle=True
)

test_loader = DataLoader(
    datasets.CIFAR10("./data", train=False, download=True, transform=transform),
    batch_size=BATCH_SIZE, shuffle=False
)

class SimpleCNN(nnx.Module):
    def __init__(self, rngs: nnx.Rngs):
        super().__init__()
        self.conv1 = nnx.Conv(3, 32, kernel_size=(3, 3), padding="SAME", rngs=rngs)
        self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), padding="SAME", rngs=rngs)
        self.fc1 = nnx.Linear(64 * 8 * 8, 256, rngs=rngs)
        self.fc2 = nnx.Linear(256, 10, rngs=rngs)
    
    def __call__(self, x):
        x = self.conv1(x)
        x = nnx.relu(x)
        x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2))
        x = self.conv2(x)
        x = nnx.relu(x)
        x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2))
        x = x.reshape(x.shape[0], -1)
        x = self.fc1(x)
        x = nnx.relu(x)
        x = self.fc2(x)
        return x

def compute_loss(logits, labels):
    return optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()

@nnx.jit
def train_step(graphdef, params, opt_state, batch):
    images, labels = batch
    
    def loss_fn(params):
        model = nnx.merge(graphdef, params)
        logits = model(images)
        return compute_loss(logits, labels)
    
    loss, grads = jax.value_and_grad(loss_fn)(params)
    updates, opt_state = optimizer.update(grads, opt_state, params)
    params = optax.apply_updates(params, updates)
    return graphdef, params, opt_state, loss

@nnx.jit
def eval_step(graphdef, params, batch):
    images, labels = batch
    model = nnx.merge(graphdef, params)
    logits = model(images)
    predictions = jnp.argmax(logits, axis=1)
    accuracy = jnp.mean(predictions == labels)
    return accuracy

def prepare_batch(batch):
    images = jnp.array(batch[0].numpy())
    images = jnp.transpose(images, (0, 2, 3, 1))
    labels = jnp.array(batch[1].numpy(), dtype=jnp.int32)
    return images, labels

def main():
    rngs = nnx.Rngs(42)
    model = SimpleCNN(rngs=rngs)
    graphdef, params = nnx.split(model)
    
    global optimizer
    optimizer = optax.adam(LEARNING_RATE)
    opt_state = optimizer.init(params)
    
    for epoch in range(EPOCHS):
        train_losses = []
        for batch_idx, batch in enumerate(train_loader):
            images, labels = prepare_batch(batch)
            images = jax.device_put(images, DEVICE)
            labels = jax.device_put(labels, DEVICE)
            graphdef, params, opt_state, loss = train_step(
                graphdef, params, opt_state, (images, labels)
            )
            train_losses.append(loss)
            if batch_idx % 100 == 0:
                print(f'Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss:.4f}')
        
        accuracies = []
        for batch in test_loader:
            images, labels = prepare_batch(batch)
            images = jax.device_put(images, DEVICE)
            labels = jax.device_put(labels, DEVICE)
            accuracy = eval_step(graphdef, params, (images, labels))
            accuracies.append(accuracy)
        
        avg_accuracy = np.mean(accuracies)
        print(f'Epoch {epoch+1}, Accuracy: {avg_accuracy:.4f}')
        
        if avg_accuracy > 0.5:
            print("成功")
            return True
    
    final_accuracy = np.mean(accuracies)
    print(f"最终准确率: {final_accuracy:.4f}")
    
    if final_accuracy > 0.5:
        print("成功")
        return True
    else:
        print("失败")
        return False

if __name__ == "__main__":
    main()
